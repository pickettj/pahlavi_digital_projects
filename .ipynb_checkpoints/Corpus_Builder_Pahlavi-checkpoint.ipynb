{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pahlavi Corpus Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "- [extracting MS Word data](https://towardsdatascience.com/how-to-extract-data-from-ms-word-documents-using-python-ed3fbb48c122)\n",
    "- [navigating MS Word XML data](https://virantha.com/2013/08/16/reading-and-writing-microsoft-word-docx-files-with-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because some of this code uses the walrus operator, it requires Python3.8; [expanation for how to deal with installation](https://github.com/pickettj/jupyter_notebooks/blob/master/README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile, re, glob, nltk, pickle\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "# explanation of default dict: https://www.geeksforgeeks.org/defaultdict-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set home directory path\n",
    "hdir = os.path.expanduser('~')\n",
    "\n",
    "#pahlavi corpus directory\n",
    "pah_path = hdir + \"/Box/Notes/Digital_Humanities/Corpora/pahlavi_corpus/\"\n",
    "\n",
    "#pickle path\n",
    "pickle_path = hdir + \"/Box/Notes/Digital_Humanities/Corpora/pickled_tokenized_cleaned_corpora\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glob the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_files = glob.glob(pah_path + r'/*.docx')\n",
    "\n",
    "pah_xml_corpus = {}\n",
    "for longname in pah_files:\n",
    "    document = zipfile.ZipFile(longname)\n",
    "    txt = zipfile.ZipFile.read(document, 'word/document.xml', pwd=None)\n",
    "    start = os.path.basename(longname)\n",
    "    short = os.path.splitext(start)\n",
    "    pah_xml_corpus[short[0]] = txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble simple corpus divided by MS Word paragraph breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [new version](https://github.com/pickettj/pahlavi_digital_projects/issues/3) takes advantage of the \"[walrus operator](https://medium.com/better-programming/what-is-the-walrus-operator-in-python-5846eaeb9d95#:~:text=Nov%2010%2C%202019%20%C2%B7%202%20min,would%20utilize%20a%20similar%20statement.),\" which allows the \"assignment and return of a value on the same expression.\"\n",
    "\n",
    "Essentially, the walrus operator [takes something like this](https://realpython.com/lessons/assignment-expressions/):\n",
    "\n",
    "```python\n",
    "walrus = False\n",
    "print (walrus)\n",
    "```\n",
    "\n",
    "And consolidates it into this:\n",
    "\n",
    "```python\n",
    "print (walrus := False)\n",
    "```\n",
    "\n",
    "Here's a version of the below code in a single line:\n",
    "\n",
    "```python\n",
    "pahlavi_corpus = {\n",
    "    name: [\n",
    "        t for p in BeautifulSoup(src).find_all(\"w:p\") if len(t := p.get_text()) > 0\n",
    "    ] for name, src in pah_xml_corpus.items()\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "For posterity, previous version:\n",
    "\n",
    "```python\n",
    "pahlavi_corpus = {}\n",
    "for work in pah_xml_corpus:\n",
    "    tree = BeautifulSoup(pah_xml_corpus[work])\n",
    "    paras = tree.find_all(\"w:p\")\n",
    "    document = {}\n",
    "    for i in range(len(paras)):\n",
    "        if len(paras[i].get_text()) > 0:\n",
    "            document[i] = paras[i].get_text()\n",
    "    pahlavi_corpus[work] = document\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pahlavi_corpus = {}\n",
    "for name, src in pah_xml_corpus.items():\n",
    "    tree = BeautifulSoup(src)\n",
    "    paras = tree.find_all(\"w:p\")\n",
    "    document = [t for p in paras if len(t := p.get_text()) > 0]\n",
    "    pahlavi_corpus[name] = document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nĪrang ī āb',\n",
       " 'Also WD.89',\n",
       " '[ML / 4050 / 303v]',\n",
       " '[TUL 11263_294r]',\n",
       " '[DZ 4010_ 292r]',\n",
       " '[Nik 4040_ 294v]',\n",
       " ' Nīrang ī āb ud pādyāb yaštan',\n",
       " 'fradom kār ēn kū ōy kū āb ud  pādyāb // kunēd naxust xwēš-tan pad baršnūm bē abāyēd šustan ',\n",
       " 'ud ka-š // 3 3 \\\\\\\\ 3 šabag dāšt bawēd āb pad karbās  ī pad-pādyāb pālūdan ud pad  ǰāmag ī // \\\\\\\\ pad-pādyāb andar kunišn ',\n",
       " 'gōmēz  az gāw ī gušn ka nē ān ī wādag  // šāyēd \\\\\\\\ bē kunišn ',\n",
       " 'ud andar ǰāmag ī pad-pādy<āb  xūbīhā andar kunišn ',\n",
       " 'u-š sar  // \\\\\\\\ bē nihumbišn ud az xrafstar ud abārīg  rēmanīh pad pahrēz dārišn ',\n",
       " 'ud aw>ēšān kē āb  // \\\\\\\\ ud g[ōmēz yazēnd yaštan tan p<ad baršnūm bē šōyišn ',\n",
       " 'ka 3 3 3 > šabag xub [dāšt // ēg-išān 30 <gām frāz kunišn ',\n",
       " 'yašt ī 3 paywa \\\\\\\\ nd abāg kas ī h[u-xēmtar ī awest<wārtar ī // rāst>-Abestāg \\\\\\\\ tar (narm-Abestāg-tar) xūb-n[ērangtar ud dēn-āgāhtar [ML_304r] bē < kunišn // ',\n",
       " 'ud ān kas kē zōdīh k>unēd šab<[īg kustīg nōg ud pad-pādyāb < ōy-iz kē rāspīg // ud srōš>-barišnīh kun\\\\\\\\ēd hamgōnag [ǰāmag ī nōg kustī<g nōg abāyēd ∵ ',\n",
       " 'ōy tan kē Abe>stāg- // warmtar \\\\\\\\ [TUL_294v] zōdīh kunēd ōy ayār ',\n",
       " '< u-šā]n ēk abāyēd kū-š > ǰud-dēw-dād // warm \\\\\\\\ ud ēk bār pad zō]dīh xwē<š yašt estēd nōg sāzi>šn',\n",
       " 'pād\\\\\\\\yābīh // ān čim rāy] mādagwar<īhā abāyēd ka yazišn sā>xt āb ud \\\\\\\\ gōmēz kē bē] // āwarišn az kustag ī dašn zōd az sar ī barsom ta]\\\\\\\\y ī ādišt andarg // bē nihišn ',\n",
       " 'ōy kē zōdīh kāmēd kerdan dast pad-pādyāb bē kunišn ēk bār // gōmēz ud āb bē nigerišn',\n",
       " 'ud hamāg \\\\\\\\ gyāgīhā pēš gōmēz pas āb nigerišn // ',\n",
       " 'hamāg gyāgīhā ān ī wāzag kē ō pēš nibēsam bē gōwišn bē estišn // gōmēz ud āb bē nigerišn \\\\\\\\ ',\n",
       " 'pas Abestāg bē rāyēnišn ',\n",
       " 'didīgar bār pad gāh // ī ādarwaxšān ān \\\\\\\\ [Nik_ 295r] gy<āg kū humāiiehe . pairi . jaθnō . // > b<ē estišn ',\n",
       " 'u-š \\\\\\\\ war an>dar hamāg sāzišn kunišn aṣ̌əm .> bē gōwišn ',\n",
       " 'didīgar bār hamāg xūb // \\\\\\\\ bē < nigerišn ',\n",
       " 'u-š ātaxš-gāh šustan u>-š dast pad-pādyāb abāz kerd<an ∵ yaθā . // ahū . vairiiō . 2 andar > rāh ēd bē gōwišn ',\n",
       " 'ō pas bars<om šawēd u-š tarsag // āhīhā bē e>stišn',\n",
       " 'ud sidīgar bār sāzišn \\\\\\\\ gō<mēz ud āb xūb bē nigerišn u-š . fra // s>tuiiē . bē gōwišn ',\n",
       " 'u-š \\\\\\\\ č<ahārom bār xūb bē nige>r<išn ',\n",
       " 'bawēd kē > guft kū // pad Yatāhūwērō p<ad š́iiaōθnən]ąm .> 4-g<ānag pad ēk bār bē nigerišn // \\\\\\\\ ',\n",
       " 'p<as Abestāg bē] rāyēnišn ',\n",
       " 'ud > pad ńiuuaēδaiiemi . bun bē nigerišn ',\n",
       " 'ud \\\\\\\\ [DZ_ 292r] p<as Abestā]g bē rāyēnišn',\n",
       " 'ud > pad ān ī Ašemwohū [ML_304v] 3-(gānag pad) bun ī hōm<āst // b<ē nigerišn] ',\n",
       " 'pas barəsm>ana . bun kunišn ',\n",
       " 'bawēd kē 6 gyāg gōwēd] \\\\\\\\ 4 < kē azabar // nibišt ',\n",
       " '2 kē (bē ō) pēš gōwēd 5-om pad ān ī wāz gīr]išn\\\\\\\\īh ī pad hōm<āst sar ',\n",
       " 'ud > hamāg // [TUL_295r] xūb bē [nigerišn ∵ ',\n",
       " 'pas pad bun ī fragard \\\\\\\\ wāzag ī pad bu<n ī ǰud-dēw-d>ād mraot̰ . bē // < gō[wišn > bē estišn ',\n",
       " 'hamāg xūb bē nigerišn hamāg gyāg pēš gōmēz ud pas āb // [nigerišn ',\n",
       " 'pas k<a \\\\\\\\ nihuftag estēd weh-iz bawēd tā yazišn sar ān ī g[yāg dārišn // pad \\\\\\\\ šāyist nē šāyist ',\n",
       " 'hamāg wizend ī andar yazišn rasēd ham-čiyōn [yašt nōg \\\\\\\\ nābar u-š xšnūman // Srōš kunēd ā-šāyēd ',\n",
       " 'u-š  ǰāmag 2 pad-pād<yāb> kē az ān ī āb   ud gōmēz pad-pādyab grift estēd andar aw-iš  // kunišn',\n",
       " 'harw \\\\\\\\ gyāg kū andar yazišn ēd nigerišn abāyēd // ',\n",
       " 'az ān gyāg ǰāmag kē āb ud gōmēz \\\\\\\\ pad-pādyāb andar andak-ēw pad dīdār ī zōd ōwōn kē // wēnēd ',\n",
       " 'andar ān ī gōmēz gōmēz \\\\\\\\ [Nik_ 295v] andar ān ī āb āb rēzišn kū xw<ārtar bawēd ',\n",
       " 'ka // yazišn xūbīh>ā f\\\\\\\\razāmīh abar āyēd ān āb ud < gōmēz yaštag ō gyāg ī  kū // xwēš-kā>rīh ast barēnd ',\n",
       " 'ud pad karbās-ēw ī nōg ī pad-pādyāb  < kerd estēd ān ǰāmag > ī // āb ud gōmēz andar ast sar xūbīhā bastan < kū az gōmēz bērōn andar a>w-iš nē šawēd // \\\\\\\\ ',\n",
       " '(pad ēč rāh ud) pad ēč tis sūdagīh nē kerdan čē-š < bun hamāg pādyābīh-ēw padiš // ast ∵ \\\\\\\\ ',\n",
       " 'hamāg tis-iz nigerišnīg padiš ker[dan ',\n",
       " 'M<ēdyō>māh ēn-iz guft kū // pad f\\\\\\\\ragard 9 10-om ī ǰud-d[ēw-dād < ān gyāg > kū Yatāhūwēryō 100-gānag \\\\\\\\ aṣ̌ēm . vohū . 100-// -gānag ',\n",
       " 'a[st kū 300 sag ī pad pādyāb // bawēd \\\\\\\\ ',\n",
       " 'pad harw Ašemwohū’ān ēk ',\n",
       " 'ud pad h[arw yaθā . ahū . vairii\\\\\\\\ō . ēk // sag andar gōmēz āb [ML_305r] abaganēd ',\n",
       " 'u-š baxšišn nē [āmār bē \\\\\\\\ agar ō gōmēz // wēš abganēd šāyēd ',\n",
       " 'pad čāštag ī Abarg guf[t \\\\\\\\ sag ī nē abāyēd abganēd // ',\n",
       " 'pad čāštag ī Mēdyōmāh abāyēd abganēd [pad amahrspandān yazdān kām bawād ∵ ',\n",
       " '[TUL 11263_295v col.]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "pahlavi_corpus[\"nĪrang ī āb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Line Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently does not work for works that lack line numbers, e.g. nĪrang ī āb\n",
    "\n",
    "num_pattern = re.compile(r'^(.*(?:\\.[0-9]{1,3}){1,3})?(.*)')\n",
    "\n",
    "pahlavi_corpus_lines = {}\n",
    "\n",
    "for name, doc in pahlavi_corpus.items():\n",
    "    match = [ret.groups() for text in doc if (ret := num_pattern.match(text)) is not None]\n",
    "\n",
    "    if all(num is None for num, text in match):\n",
    "        # this doc doesn't use line numbers, make our own\n",
    "        pahlavi_corpus_lines[name] = {str(i+1): text for i, (_, text) in enumerate(match)}\n",
    "        continue\n",
    "\n",
    "    segment = {}\n",
    "    para, line = None, None\n",
    "\n",
    "    for i, (num, text) in enumerate(match+[('-end-', '')]):\n",
    "        if num is not None:\n",
    "            if i > 0:\n",
    "                store = f'-start-' if para is None else para\n",
    "                segment[store] = line\n",
    "            para, line = num, None\n",
    "\n",
    "        if line is None:\n",
    "            line = text\n",
    "        else:\n",
    "            line += '\\n' + text\n",
    "\n",
    "    pahlavi_corpus_lines[name] = segment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pahlavi_corpus_lines.keys()\n",
    "#pahlavi_corpus_lines[\"Dēnkard 4\"]\n",
    "#pahlavi_corpus_lines.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tuples\n",
    "\n",
    "#doc = pahlavi_corpus_lines[\"ARDĀ WIRĀZ\"]\n",
    "#sum([[(ln, pos, tok) for pos, tok in enumerate(line.split())] for ln, line in doc.items()], [])\n",
    "\n",
    "# any advantage to using nltk.word_tokenize() instead of split()?\n",
    "\n",
    "pahlavi_flat_corpus = []\n",
    "for work in pahlavi_corpus_lines:\n",
    "    doc = pahlavi_corpus_lines[work]\n",
    "    output = sum([[(work, ln, pos, tok) for pos, tok in enumerate(line.split())] for ln, line in doc.items()], [])\n",
    "    pahlavi_flat_corpus += output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pahlavi_flat_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass to dataframe: pd.DataFrame([(1,2,3), (2,3,4)], columns=['a', 'b', 'c'])\n",
    "\n",
    "#pd.DataFrame(pahlavi_flat_corpus, columns=['title', 'line', 'index', 'token'])\n",
    "pd.DataFrame(pahlavi_flat_corpus, columns=['title', 'line', 'index', 'token']).to_csv(os.path.join(pickle_path,r'pahlavi_corpus.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
