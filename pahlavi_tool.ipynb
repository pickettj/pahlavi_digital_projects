{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pahlavi Tool\n",
    "James Pickett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "\n",
    "import os, re\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general function in Pandas to set maximum number of rows; otherwise it abridges and only shows a few\n",
    "\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set home directory path\n",
    "hdir = os.path.expanduser('~')\n",
    "\n",
    "#pahlavi corpus directory\n",
    "pah_path = hdir + \"/Dropbox/Active_Directories/Digital_Humanities/Corpora/pahlavi_corpus/\"\n",
    "\n",
    "#pickle path\n",
    "pickle_path = hdir + \"/Dropbox/Active_Directories/Digital_Humanities/Corpora/pickled_tokenized_cleaned_corpora\"\n",
    "\n",
    "# dataset path\n",
    "ds_path = hdir + \"/Dropbox/Active_Directories/Digital_Humanities/Datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in main corpus dataset\n",
    "df_pahcorp = pd.read_csv (os.path.join(pickle_path,r'pahlavi_corpus.csv'))\n",
    "\n",
    "#df_pahcorp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dictionary\n",
    "## Format: UID, Transcription, Translit_Mac, Translit_Skj, New Persian\n",
    "\n",
    "pahlavi_terms = pd.read_csv(ds_path + \"/exported_database_data/pahlavi_terms.csv\", names=['UID', 'Transcription', \\\n",
    "                                                'Translit_Mac', 'Translit_Skj', 'New_Persian'])\n",
    "\n",
    "## Format: UID, Term_ID, Definition\n",
    "pahlavi_definitions = pd.read_csv(ds_path + \"/exported_database_data/pahlavi_definitions.csv\", names=['UID', 'Term_ID', 'Definition'])\n",
    "\n",
    "#pahlavi_terms.sample(5)\n",
    "#pahlavi_definitions.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Terms and Definitions\n",
    "\n",
    "merged_pahdic = pd.merge(left=pahlavi_terms, right=pahlavi_definitions, how='left', left_on='UID', right_on='Term_ID')\n",
    "#merged_pahdic.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pah_help ():\n",
    "    print (\"Pahlavi Tool: Functions and Explanation\\n\\n\\\n",
    "           \\tpah_help: lists the go-to functions\\n\\\n",
    "           \\tpah_def: returns the word-match's definition ordered by frequency value in the corpus\\n\\\n",
    "           \\tkwic_pah: key word in context function\\n\\\n",
    "           \\tfreq_dic: how often does the term appear in the corpus\\n\\\n",
    "           \\tconfreq: bigram conditional frequency; optional 'group = True' argument organizes by text\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pah_help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Key Word in Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_kwic (term):\n",
    "    \n",
    "    \"\"\"This function returns a dataframe filtered by the search term.\"\"\"\n",
    "    \n",
    "    result = df_pahcorp[df_pahcorp['token'].str.match(term)]\n",
    "    return result\n",
    "    \n",
    "    # str.match; the str part is telling match how to behave; .match is a method specific to pandas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kwic_pah (term):\n",
    "    \n",
    "    for i, item in index_kwic(term).iterrows():\n",
    "        \n",
    "        title = item[\"title\"]\n",
    "        line = item[\"line\"]\n",
    "        \n",
    "        filtered = df_pahcorp[(df_pahcorp['title']==title)&(df_pahcorp['line']==line)]\n",
    "        # equivalent syntax: df_pahcorp.query(f'title == \"{title}\" and line == {line}')\n",
    "        \n",
    "        filtered = filtered.sort_values(\"index\")\n",
    "        # probably already sorted, but better to be on the safe side\n",
    "                \n",
    "        text = \" \".join(filtered[\"token\"])\n",
    "        \n",
    "        print(f'{title}: {line}\\n{text}\\n')\n",
    "        \n",
    "        # task: figure out how to color code results; termcolor package, has to be installed\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# iterrows(): research what this does exactly, has something to do with dataframes being composed of series\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kwic_pah(\"p.d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dic = pd.value_counts(df_pahcorp.token).to_frame().reset_index()\n",
    "#freq_dic.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq (term):\n",
    "    query_mask = freq_dic[\"index\"].str.contains(term, na=False)\n",
    "    query = freq_dic[query_mask]\n",
    "    result = query.head()\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq(\"p.d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addiing the frequency data into the dictionary\n",
    "\n",
    "# need to turn the transcribed word into a unique identifier (will lose some data):\n",
    "merged_pahdic_clean = merged_pahdic.drop_duplicates(subset=['Transcription'], keep='first')\n",
    "\n",
    "# merge with frequency data based on the unique identifier:\n",
    "merged_pahdic_freq = pd.merge(left=merged_pahdic, right=freq_dic, how='left', left_on='Transcription', right_on='index')\n",
    "\n",
    "# clean up for readability\n",
    "cleaned_merged_pahdic_freq = merged_pahdic_freq.drop(columns=['UID_y', 'Term_ID', 'index']).\\\n",
    "rename(columns={'UID_x': 'UID', 'token': 'Frequency'})\n",
    "\n",
    "#cleaned_merged_pahdic_freq.sample(5)\n",
    "\n",
    "# ?? how to get rid of those decimal points / why did they enter in the first place?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Definition with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pah_def (term):\n",
    "    query_mask = cleaned_merged_pahdic_freq[\"Transcription\"].str.contains(term, na=False)\n",
    "    query = cleaned_merged_pahdic_freq[query_mask]\n",
    "    result = query.sort_values('Frequency', ascending=False).head()\n",
    "    return (result)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pah_def(\"p.d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confreq (term, group=False):\n",
    "    sel = df_pahcorp[df_pahcorp['token']==term].copy()\n",
    "    sel['index_next'] = sel['index'] + 1\n",
    "    sel = sel.join(\n",
    "        df_pahcorp.set_index(['title', 'line', 'index'])['token'].rename('token_next'),\n",
    "        on=['title', 'line', 'index_next']\n",
    "    )\n",
    "    # If there are only 1-frequency results, it will still show them;\n",
    "    # but if there are enough higher frequency results, it will omit the 1-frequency results.\n",
    "    result = sel['token_next'].value_counts()\n",
    "    short_result = [(x,y) for x,y in result.items() if y > 1]\n",
    "    if len(short_result) > 5:\n",
    "        result = short_result\n",
    "    # improvement: create a list of omitted words (e.g. ud, Ä«, etc.), and make a flag1=False\n",
    "    # optional argument to omit them.\n",
    "    \n",
    "    if group == True:\n",
    "        result = sel.groupby('title')['token_next'].value_counts().rename(\"count\").reset_index()\n",
    "    \n",
    "    return (result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confreq ('may', group = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pahlavi Tool: Functions and Explanation\n",
      "\n",
      "           \tpah_def: returns the word-match's definition ordered by frequency value in the corpus\n",
      "           \tkwic_pah: key word in context function\n",
      "           \tfreq_dic: how often doses the term appear in the corpus\n",
      "           \tconfreq: bigram conditional frequency; optional 'group = True' argument organizes by text\n"
     ]
    }
   ],
   "source": [
    "pah_help()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
