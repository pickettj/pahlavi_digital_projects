{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pahlavi Corpus Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "- [extracting MS Word data](https://towardsdatascience.com/how-to-extract-data-from-ms-word-documents-using-python-ed3fbb48c122)\n",
    "- [navigating MS Word XML data](https://virantha.com/2013/08/16/reading-and-writing-microsoft-word-docx-files-with-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile, re, glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set home directory path\n",
    "hdir = os.path.expanduser('~')\n",
    "\n",
    "#pahlavi corpus directory\n",
    "pah_path = hdir + \"/Box/Notes/Digital_Humanities/Corpora/pahlavi_corpus/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glob the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_files = glob.glob(pah_path + r'/*.docx')\n",
    "\n",
    "pah_xml_corpus = {}\n",
    "for longname in pah_files:\n",
    "    document = zipfile.ZipFile(longname)\n",
    "    txt = zipfile.ZipFile.read(document, 'word/document.xml', pwd=None)\n",
    "    start = os.path.basename(longname)\n",
    "    short = os.path.splitext(start)\n",
    "    pah_xml_corpus[short[0]] = txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble simple corpus divided by MS Word paragraph breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pahlavi_corpus = {}\n",
    "for work in pah_xml_corpus:\n",
    "    tree = BeautifulSoup(pah_xml_corpus[work])\n",
    "    paras = tree.find_all(\"w:p\")\n",
    "    document = {}\n",
    "    for i in range(len(paras)):\n",
    "        if len(paras[i].get_text()) > 0:\n",
    "            document[i] = paras[i].get_text()\n",
    "    pahlavi_corpus[work] = document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.18.1abar xwēdōdah kū '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pah_xml_corpus['Dēnkard 1']\n",
    "\n",
    "pahlavi_corpus[\"Dēnkard 5\"][203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary comprehension for simple search, i.e. retain all lines that contain a string\n",
    "# Parse base on actual line using regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
